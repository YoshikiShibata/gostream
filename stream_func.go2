// Copyright Â© 2020 Yoshiki Shibata. All rights reserved.

package gostream

import (
	"constraints"
	"sort"
	"sync"
)

// Map returns a stream consisting of the results of applying the given
// function to the elements of the given stream.
func Map[T, R any](stream Stream[T], mapper Function[T, R]) Stream[R] {
	gs := stream.(*genericStream[T])
	gs.validateState()

	nextReq := make(chan struct{})
	nextData := make(chan orderedData[R])

	closeCounter := gs.parallelCount
	var lock sync.Mutex

	closeChans := func() {
		lock.Lock()
		defer lock.Unlock()

		if closeCounter > 1 {
			closeCounter--
			return
		}

		close(nextData)
		close(gs.nextReq)
		go func() {
			for range nextReq {
			}
		}()
	}

	parallelCount := gs.parallelCount
	for i := 0; i < parallelCount; i++ {
		go func() {
			for range nextReq {
				gs.nextReq <- struct{}{}
				od, ok := <-gs.nextData
				if !ok {
					closeChans()
					return
				}
				r := mapper(od.data)
				nextData <- orderedData[R]{
					order: od.order,
					data:  r,
				}
			}
		}()
	}

	return &genericStream[R]{
		parallel:      gs.parallel,
		parallelCount: parallelCount,
		nextReq:       nextReq,
		nextData:      nextData,
	}
}

// FlatMap returns a stream consisting of the results of replacing each
// element of stream with the contents of mapped stream produced by applying
// the provided mapping function to each element.
func FlatMap[T, R any](
	stream Stream[T],
	mapper Function[T, Stream[R]],
) Stream[R] {
	gs := stream.(*genericStream[T])
	gs.validateState()

	nextReq := make(chan struct{})
	nextData := make(chan orderedData[R])

	var rgs *genericStream[R]

	go func() {
		for range nextReq {
			for {
				if rgs == nil {
					gs.nextReq <- struct{}{}
					od, ok := <-gs.nextData
					if !ok {
						close(nextData)
						close(gs.nextReq)
						go func() {
							for range nextReq {
							}
						}()
						return
					}

					r := mapper(od.data)
					rgs = r.(*genericStream[R])
				}

				rgs.nextReq <- struct{}{}
				r, ok := <-rgs.nextData
				if !ok {
					close(rgs.nextReq)
					rgs = nil
				} else {
					nextData <- r
					break
				}
			}
		}
	}()

	return &genericStream[R]{
		parallelCount: 1,
		nextReq:       nextReq,
		nextData:      nextData,
	}
}

// Returns a sequential ordered stream whose elements are the specified
// values.
func Of[T any](data ...T) Stream[T] {
	nextReq := make(chan struct{})
	nextData := make(chan orderedData[T])

	go func() {
		i := 0
		for range nextReq {
			if i == len(data) {
				close(nextData)
				go func() {
					for range nextReq {
					}
				}()
				return
			}
			if i < len(data) {
				nextData <- orderedData[T]{
					order: uint64(i),
					data:  data[i],
				}
				i++
			}
		}
		close(nextData)
	}()

	return &genericStream[T]{
		parallelCount: 1,
		nextReq:       nextReq,
		nextData:      nextData,
	}
}

// Distinct returns a stream consisting of the distinct elements
// (according to ==) of this stream.
func Distinct[T comparable](stream Stream[T]) Stream[T] {
	s := stream.(*genericStream[T])
	s.validateState()

	gs := &genericStream[T]{
		parallelCount: 1,
		prevReq:       s.nextReq,
		prevData:      s.nextData,
		nextReq:       make(chan struct{}),
		nextData:      make(chan orderedData[T]),
	}

	closeChans := func() {
		for i := 0; i < (s.parallelCount - 1); i++ {
			s.nextReq <- struct{}{}
		}
		gs.close()
	}

	go func() {
		seen := make(map[T]bool)

		for range gs.nextReq {
			od, ok := gs.getPrevData()
			if !ok {
				closeChans()
				return
			}

			for seen[od.data] {
				od, ok = gs.getPrevData()
				if !ok {
					closeChans()
					return
				}
			}
			gs.nextData <- od
			seen[od.data] = true
		}
		closeChans()
	}()

	return gs
}

// Sorted returns a stream consisting of the elements of stream, sorted
// according to natural order.
func Sorted[T constraints.Ordered](stream Stream[T]) Stream[T] {
	s := stream.(*genericStream[T])
	s.validateState()

	prevReq := s.nextReq
	prevData := s.nextData

	var dataSlice []T
	for {
		prevReq <- struct{}{}
		od, ok := <-prevData
		if !ok {
			break
		}
		dataSlice = append(dataSlice, od.data)
	}
	close(prevReq)

	sort.Slice(dataSlice, func(i, j int) bool {
		return dataSlice[i] < dataSlice[j]
	})

	return Of(dataSlice...)
}

// Reduce performs a reduction on the elements of stream, using the provided
// identity, accumulation and combining functions.
func Reduce[U, T any](
	stream Stream[T],
	identity U,
	accumulator BiFunction[U, T, U],
	combiner BinaryOperator[U],
) U {
	s := stream.(*genericStream[T])
	s.validateState()

	prevReq := s.nextReq
	prevData := s.nextData

	// parallel execution is not implemented yet.
	// When the parallel execution is supported, then
	// uncomment this line out.
	//
	// gomaxprocs := runtime.GOMAXPROCS(-1)

	gomaxprocs := 1
	results := make(chan U, gomaxprocs)
	var wg sync.WaitGroup
	wg.Add(gomaxprocs)

	for i := 0; i < gomaxprocs; i++ {
		go func() {
			defer wg.Done()

			result := identity
			for {
				prevReq <- struct{}{}
				od, ok := <-prevData
				if !ok {
					break
				}
				result = accumulator(result, od.data)
			}
			results <- result
		}()
	}
	wg.Wait()

	close(prevReq)
	close(results)

	result := identity
	for r := range results {
		result = combiner(result, r)
	}

	return result
}

// Collect performs mutable reduction opertion on the elements of stream. A
// mutable result is one in which reduced value is a mutable result container
// such as a slice.
func Collect[R, T any](
	stream Stream[T],
	supplier Supplier[R],
	accumulator BiConsumer[R, T],
	combiner BiConsumer[R, R],
) R {
	s := stream.(*genericStream[T])
	s.validateState()

	prevReq := s.nextReq
	prevData := s.nextData

	// parallel execution is not implemented yet.
	// When the parallel execution is supported, then
	// uncomment this line out.
	//
	// gomaxprocs := runtime.GOMAXPROCS(-1)

	gomaxprocs := 1
	results := make(chan R, gomaxprocs)
	var wg sync.WaitGroup
	wg.Add(gomaxprocs)

	for i := 0; i < gomaxprocs; i++ {
		go func() {
			defer wg.Done()

			result := supplier()
			for {
				prevReq <- struct{}{}
				od, ok := <-prevData
				if !ok {
					break
				}
				accumulator(result, od.data)
			}
			results <- result
		}()
	}
	wg.Wait()

	close(prevReq)
	close(results)

	result := supplier()
	for r := range results {
		combiner(result, r)
	}

	return result
}

// CollectByCollector performs mutable reduction operation on the elements of
// stream using a Collector. A Collector encapsulates the functions used as
// arguments to Collect(Supplier, BiConsumer, BiConsumer), allowing for
// resuse of collection strategies and composition of collect operations such
// as multiple-level grouping or partitioning.
func CollectByCollector[T, R, A any](
	stream Stream[T],
	collector *Collector[T, A, R],
) R {
	supplier := collector.Supplier()
	accumulator := collector.Accumulator()
	combiner := func(r, t A) {
		_ = collector.Combiner()(r, t)
	}

	a := Collect(stream, supplier, accumulator, combiner)
	return collector.Finisher()(a)
}

// Empty returns an empty Stream
func Empty[T any]() Stream[T] {
	gs := &genericStream[T]{
		parallelCount: 1,
		nextReq:       make(chan struct{}),
		nextData:      make(chan orderedData[T]),
	}

	go func() {
		for range gs.nextReq {
			// discard all requests
		}
	}()

	close(gs.nextData)
	return gs
}

// Iterate returns an infinite sequential ordered Stream produces by iterative
// appliation of a function f to an initial element seed, producing a Stream
// consisiting of seed, f(seed), f(f(seed)), etc.
func Iterate[T any](seed T, f UnaryOperator[T]) Stream[T] {
	gs := &genericStream[T]{
		parallelCount: 1,
		nextReq:       make(chan struct{}),
		nextData:      make(chan orderedData[T]),
	}

	go func() {
		useSeed := true
		nextValue := seed

		order := uint64(0)
		for range gs.nextReq {
			if useSeed {
				gs.nextData <- orderedData[T]{
					order: order,
					data:  seed,
				}
				useSeed = false
			} else {
				nextValue = f(nextValue)
				gs.nextData <- orderedData[T]{
					order: order,
					data:  nextValue,
				}
			}
			order++
		}
		close(gs.nextData)
	}()

	return gs
}

// IterateN returns a sequential ordered Stream produced by iterative
// application of the given next function to an initial element,
// conditioned on satisfying the given code hasNext predicate.
// stream terminates as soon as the code hasNext predicate returns false.
func IterateN[T any](
	seed T,
	hasNext Predicate[T],
	next UnaryOperator[T]) Stream[T] {

	gs := &genericStream[T]{
		parallelCount: 1,
		nextReq:       make(chan struct{}),
		nextData:      make(chan orderedData[T]),
	}

	go func() {
		nextValue := seed
		applyNext := false

		order := uint64(0)
		for range gs.nextReq {
			if applyNext {
				nextValue = next(nextValue)
			}

			if !hasNext(nextValue) {
				break
			}

			gs.nextData <- orderedData[T]{
				order: order,
				data:  nextValue,
			}
			order++
			applyNext = true
		}
		close(gs.nextData)
	}()

	return gs
}

// Generate returns an infinite sequential unordered stream where each element
// is generated by the provided Supplier.  This is suitable for generating
// constant streams, streams of random elements, etc.
func Generate[T any](s Supplier[T]) Stream[T] {
	gs := &genericStream[T]{
		parallelCount: 1,
		nextReq:       make(chan struct{}),
		nextData:      make(chan orderedData[T]),
	}

	go func() {
		order := uint64(0)
		for range gs.nextReq {
			gs.nextData <- orderedData[T]{
				order: order,
				data:  s(),
			}
			order++
		}
		close(gs.nextData)
	}()

	return gs
}

// Concat a lazily concatenated stream whose elements are all the elements of
// the first stream followed by all the elements of the second stream.
func Concat[T any](a, b Stream[T]) Stream[T] {
	ags := a.(*genericStream[T])
	bgs := b.(*genericStream[T])
	ags.validateState()
	bgs.validateState()

	gs := &genericStream[T]{
		parallelCount: 1,
		nextReq:       make(chan struct{}),
		nextData:      make(chan orderedData[T]),
	}

	go func() {
		gs.prevReq = ags.nextReq
		gs.prevData = ags.nextData
		switchedToB := false

		for range gs.nextReq {
			data, ok := gs.getPrevData()
			if !ok {
				if switchedToB {
					gs.close()
					return
				}

				gs.prevReq = bgs.nextReq
				gs.prevData = bgs.nextData
				switchedToB = true

				data, ok = gs.getPrevData()
				if !ok {
					gs.close()
					return
				}
			}
			gs.nextData <- data
		}
		gs.close()
	}()

	return gs
}
